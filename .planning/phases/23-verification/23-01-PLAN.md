---
phase: 23-verification
plan: 01
type: execute
---

<objective>
Verify parallel training correctness and measure performance improvement.

Purpose: Ensure parallel mode produces identical results to serial mode (given same seeds) and document the speedup achieved by worker parallelization.
Output: Passing verification tests + documented performance benchmarks.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase summaries (dependencies):
@.planning/phases/20-simulator-exports/20-01-SUMMARY.md
@.planning/phases/21-worker-infrastructure/21-01-SUMMARY.md
@.planning/phases/22-cli-integration/22-01-SUMMARY.md

# Key files from parallel training implementation:
@packages/ai-trainer/src/simulator.ts
@packages/ai-trainer/src/parallel-simulator.ts
@packages/ai-trainer/src/simulation-worker.ts
@packages/cli/src/commands/train-ai.ts

**Tech stack available:**
- Node.js worker_threads (built-in)
- SeededRandom class for deterministic simulation
- Vitest for testing

**Established patterns:**
- Seed format: `${baseSeed}-game-${i}` for deterministic game ordering
- Work-stealing pattern in parallel-simulator.ts
- Features regenerated from serialized structure in workers

**Constraining decisions:**
- Phase 20: Features regenerated in workers from serialized structure
- Phase 21: Work-stealing pattern (not fixed batch assignment)
- Phase 22: CLI bypasses AITrainer for parallel mode

**Verification focus:**
- Same seed + same game count â†’ same GameData results (order-independent)
- Parallel mode achieves significant speedup vs serial
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add parallel simulator unit tests</name>
  <files>packages/ai-trainer/tests/parallel-simulator.test.ts</files>
  <action>
Create unit tests for the parallel simulator that verify:

1. **Determinism test** - Same seed produces same aggregate results regardless of worker count:
   - Run 10 games with seed "test-determinism" using 1 worker
   - Run 10 games with seed "test-determinism" using 2 workers
   - Compare: same total completedGames, same totalStates, same averageActions
   - Note: Individual game order may differ due to work-stealing, but aggregate stats must match

2. **Result aggregation** - All games are collected correctly:
   - Run N games, verify results.games.length === N
   - Verify each game has required fields (gameId, playerCount, states, winners, totalActions, completed)

3. **Worker count bounds** - Edge cases handled:
   - workerCount of 1 works (serial via workers)
   - workerCount > gameCount caps to gameCount

Use go-fish game for testing (simplest game, fastest to simulate). Import the game module path dynamically like the CLI does.

Test file structure:
```typescript
import { describe, it, expect } from 'vitest';
import { runParallelSimulations } from '../src/parallel-simulator.js';
// ... setup code to find go-fish module path
```

Set test timeout to 60000ms (parallel simulation can take time).
  </action>
  <verify>pnpm --filter @boardsmith/ai-trainer test -- parallel-simulator.test.ts passes</verify>
  <done>Unit tests pass: determinism verified, result aggregation correct, edge cases handled</done>
</task>

<task type="auto">
  <name>Task 2: Run benchmark and document results</name>
  <files>packages/ai-trainer/README.md</files>
  <action>
1. Run train-ai command with and without --parallel flag on go-fish game to capture timing:
   - Serial: `time npx boardsmith train-ai --games 50 --iterations 1`
   - Parallel: `time npx boardsmith train-ai --games 50 --iterations 1 --parallel`

2. Record the timings and calculate speedup factor.

3. Update the ai-trainer README.md to document the parallel training feature:
   - Add section on parallel training usage
   - Document the --parallel and --workers flags
   - Include benchmark results showing speedup
   - Note the determinism guarantee (same seed = same results)

Keep the documentation concise and practical.
  </action>
  <verify>README.md contains parallel training documentation with actual benchmark numbers</verify>
  <done>Parallel training documented with usage instructions and performance benchmarks</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `pnpm --filter @boardsmith/ai-trainer test` passes (includes new parallel tests)
- [ ] `pnpm test` passes (all tests still work)
- [ ] README.md has parallel training documentation
- [ ] Benchmark numbers are realistic (parallel faster than serial)
</verification>

<success_criteria>

- Parallel simulator tests pass demonstrating correctness
- Determinism verified (same seed = same aggregate results)
- Performance improvement documented with real numbers
- ai-trainer README updated with parallel training guide
- Phase 23 complete, v0.9 milestone ready for shipping
</success_criteria>

<output>
After completion, create `.planning/phases/23-verification/23-01-SUMMARY.md`:

# Phase 23 Plan 01: Verification Summary

**[Substantive one-liner about what was verified and documented]**

## Accomplishments

- [Test results]
- [Benchmark results]
- [Documentation updates]

## Files Created/Modified

- `packages/ai-trainer/tests/parallel-simulator.test.ts` - Unit tests
- `packages/ai-trainer/README.md` - Parallel training docs

## Decisions Made

[Any decisions about test approach or documentation]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

Phase complete, v0.9 milestone ready for shipping.
</output>
